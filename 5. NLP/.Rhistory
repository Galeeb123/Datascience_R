library(tidyverse)
library(MASS)
data("mtcars")
? mtcars
View(mtcars)
mpgModel_wt = lm(formula = mpg ~ wt, data = mtcars)
plot(mpgModel_wt, which =1)
mpgModel_all = lm(formula = mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb, data = mtcars)
data (" mtcars ")
? mtcars
View ( mtcars )
mpgModel = lm(formula = mpg ~ cyl + disp +hp+ drat +wt+ qsec +vs+am+ gear +carb,data = mtcars)
summary (mpgModel)
eruptionModel = lm(eruptions ~ waiting, data = faithful)
library(tidyverse)
library(MASS)
data("faithful")
str(faithful)
summary(faithful)
ggplot(data = faithful ,aes(x = waiting , y = eruptions)) + geom_point()
cor.test(faithful$waiting, faithful$eruptions)
eruptionModel = lm(eruptions ~ waiting, data = faithful)
eruptionModel
layout(matrix (1:6, ncol = 2, byrow = TRUE))
plot(eruptionModel, 1:6)
plot ( womenModel , which =1)
ggplot(data = women,aes(x = weight,y = height)) +geom_point() +geom_abline(mapping = aes(slope = womenModel$coefficients [2],intercept = womenModel$coefficients[1]), color ='red ')
library ( tidyverse )
library ( MASS )
data (" women ")
str ( women )
summary (women)
ggplot ( data = women , aes (x = weight , y = height )) + geom_point ()
cor.test(women$weight,women$height)
womenModel = lm(height ~ weight, data = women)
womenModel
summary(womenModel)
ggplot(data = women,aes(x = weight,y = height)) +geom_point() +geom_abline(mapping = aes(slope = womenModel$coefficients [2],intercept = womenModel$coefficients[1]), color ='red ')
plot ( womenModel , which =1)
cor.test(women$weight,women$height)
womenModel = lm(height ~ weight, data = women)
womenModel
summary(womenModel)
library ( tidyverse )
library ( MASS )
data (" women ")
str ( women )
women
women
women$predicted_height = predict(womenModel, newdata = women$weight)
library(tidyverse)
library(MASS)
data("mtcars")
? mtcars
View(mtcars)
mpgModel_wt = lm(formula = mpg ~ wt, data = mtcars)
plot(mpgModel_wt, which =1)
# Creating a data frame with actual values and predicted values.
mpgPredictions_wt = data.frame(mpg = mtcars$mpg, pred = mpgModel_wt$fitted.values)
mpgPredictions_wt
women$predicted_height = data.frame(predict(womenModel, newdata = women$weight))
womenModel$fitted.values
women$pred_height = womenModel$fitted.values
women$pred_height = womenModel$fitted.values
women
women$pred_height = womenModel$fitted.values
women
women$residuals = womenModel$height - women$pred_height
women$residuals = women$height - women$pred_height
women
women$residuals = women$height - women$pred_height
women
ggplot ( data = women , aes (x = pred_height , y = residuals )) + geom_point ()
mpgModel_wt = lm(formula = mpg ~ wt, data = mtcars)
mpgModel
plot(mpgModel_wt, which =1)
ggplot(data = mpgPredictions_wt, aes(x = mpg , y = pred)) + geom_point() + geom_abline(mapping = aes(slope = 1, intercept = 0), color ='red ')
summary(mpgModel_wt)
mpgModel_all = lm(formula = mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb, data = mtcars)
plot(mpgModel_all, which =1)
# Creating a data frame with actual values and predicted values.
mpgPredictions_all = data.frame(mpg = mtcars$mpg, pred = mpgModel_all$fitted.values)
mpgPredictions_all
ggplot(data = mpgPredictions_all, aes(x = mpg , y = pred)) + geom_point() + geom_abline(mapping = aes(slope = 1, intercept = 0), color ='red ')
summary(mpgModel_all)
reducedModel  = step(mpgModel_all, direction ="backward")
# Creating a data frame with actual values and predicted values.
mpgPredictions = data.frame(mpg = mtcars$mpg, pred_ConsideringOnlyWeight = mpgModel_wt$fitted.values, pred_ConsideringAll = mpgModel_all$fitted.values, pred_UsingStepFun = reducedModel$fitted.values)
mpgPredictions
summary(reducedModel)
# Creating a data frame with actual values and predicted values.
mpgPredictions = data.frame(mpg = mtcars$mpg, pred_ConsideringOnlyWeight = mpgModel_wt$fitted.values, pred_ConsideringAll = mpgModel_all$fitted.values, pred_UsingStepFun = reducedModel$fitted.values)
mpgPredictions
# Creating a data frame with actual values and predicted values.
mpgPredictions_wt = data.frame(mpg = mtcars$mpg, pred = mpgModel_wt$fitted.values)
mpgPredictions_wt
summary(mpgModel_wt)
mpgModel_all = lm(formula = mpg ~ cyl + disp + hp + drat + wt + qsec + vs + am + gear + carb, data = mtcars)
plot(mpgModel_all, which =1)
View(mtcars)
newWomen = data.frame(weight =c(130 , 170,100))
predict( womenModel , newdata = newWomen )
women
women$new_predicted = data.frame(women[1:15,2])
predict( womenModel , newdata = women$new_predicted )
women$new_predicted = data.frame(women[2:15,2])
new_predicted = data.frame(women[2:15,2])
predict( womenModel , newdata = new_predicted )
new_data = women$weight
predict(womenModel, newdata = new_data)
new_data = women$weight
new_data = women$weight
new_data
new_data = women$weight
class(new_data)
new_data = women$weight
data.frame(new_data)
new_data = women$weight
predict(womenModel, newdata = data.frame(new_data))
new_data = women$weight
predict(womenModel, newdata = data.frame(new_data))
new_data = women$weight
data.frame(new_data)
new_data = women$weight
predict(womenModel, newdata = data.frame(new_data))
new_data = women$weight
predict(womenModel, weight = data.frame(new_data))
new_data = women$weight
predict(womenModel, weight = c(new_data))
new_data = women$weight
new_pred = predict(womenModel, weight = c(new_data))
women$new_prediction=new_pred
women$new_prediction=new_pred
women
install.packages("tm") > library(tm)
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
install.packages("tm") > library(tm)
install.packages("tm")
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
install.packages("tm") > library(tm)
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
install.packages("tm") > library(tm)
install.packages("tm")
install.packages("tm") > library(tm)
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
str(docs)
summary(docs)
inspect(docs[1])
docs[[1]]
docs[[1]]$meta
docs[[1]]$content
docs = tm_map(docs, content_transformer(tolower))
docs[[1]]$content
docs =  tm_map(docs, removeWords, stopwords("english"))
docs[[1]]$content
docs =  tm_map(docs, removePunctuation)
docs[[1]]$content
trumpDTM = DocumentTermMatrix(docs)
trumpDTM
inspect(trumpDTM)
View(inspect(trumpDTM))
inspect(trumpDTM[1:2, 1:2])
trumpDTMS = removeSparseTerms(trumpDTM, 0.05)
trumpDTMS
inspect(trumpDTM[, c("news", "fake", "america", "great")])
inspect(trumpDTM[, c("free", "russia", "news")])
trumpFreqTerms = findFreqTerms(trumpDTM, lowfreq = 50)
trumpFreqTerms
trumpFreqTerms = colSums(as.matrix(trumpDTM))
head(trumpFreqTerms)
sort(trumpFreqTerms, decreasing = TRUE)
trumpFreqTermsDF =  data.frame(word = names(trumpFreqTerms), freq = trumpFreqTerms)
trumpFreqTermsDF
library("dplyr")
arrange(trumpFreqTermsDF, desc(freq))
trumpFreqTermsDF100 = subset(trumpFreqTermsDF, freq >= 100) %>% arrange(desc(freq))
barplot(trumpFreqTermsDF100$freq, names.arg = trumpFreqTermsDF100$word)
install.packages("wordcloud")
library(wordcloud)
set.seed(142)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
findAssocs(trumpDTM, "fake", corlimit = 0.6)
str(docs)
trumpDTM = DocumentTermMatrix(docs)
trumpDTM
trumpFreqTerms = colSums(as.matrix(trumpDTM))
head(trumpFreqTerms)
trumpFreqTermsDF100 = subset(trumpFreqTermsDF, freq >= 100) %>% arrange(desc(freq))
set.seed(142)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 50)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 100)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 140)
findAssocs(trumpDTM, "news", corlimit = 0.6)
install.packages("tm") > library(tm)
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
str(docs)
summary(docs)
inspect(docs[1])
docs[[1]]
docs[[1]]$content
docs[[1]]$meta
docs = tm_map(docs, content_transformer(tolower))
docs[[1]]$content
docs =  tm_map(docs, removeWords, stopwords("english"))
docs[[1]]$content
docs =  tm_map(docs, removePunctuation)
docs[[1]]$content
trumpDTM = DocumentTermMatrix(docs)
trumpDTM
inspect(trumpDTM)
inspect(trumpDTM)
View(inspect(trumpDTM))
inspect(trumpDTM[1:2, 1:2])
trumpDTMS = removeSparseTerms(trumpDTM, 0.05)
trumpDTMS
inspect(trumpDTM[, c("news", "fake", "america", "great")])
inspect(trumpDTM[, c("free", "russia", "news")])
trumpFreqTerms = findFreqTerms(trumpDTM, lowfreq = 50)
trumpFreqTerms
trumpFreqTerms = colSums(as.matrix(trumpDTM))
head(trumpFreqTerms)
sort(trumpFreqTerms, decreasing = TRUE)
trumpFreqTerms = colSums(as.matrix(trumpDTM))
trumpFreqTerms
trumpFreqTerms = colSums(as.matrix(trumpDTM))
head(trumpFreqTerms)
sort(trumpFreqTerms, decreasing = TRUE)
trumpFreqTermsDF =  data.frame(word = names(trumpFreqTerms), freq = trumpFreqTerms)
trumpFreqTermsDF
library("dplyr")
arrange(trumpFreqTermsDF, desc(freq))
trumpFreqTermsDF100 = subset(trumpFreqTermsDF, freq >= 100) %>% arrange(desc(freq))
barplot(trumpFreqTermsDF100$freq, names.arg = trumpFreqTermsDF100$word)
install.packages("wordcloud")
library(wordcloud)
library(wordcloud)
set.seed(142)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
findAssocs(trumpDTM, "fake", corlimit = 0.6)
install.packages("tm") > library(tm)
docs = Corpus(DirSource("./texts", encoding ="UTF-8"))
str(docs)
summary(docs)
inspect(docs[1])
docs[[1]]
docs[[1]]$meta
docs[[1]]$content
docs = tm_map(docs, content_transformer(tolower))
docs[[1]]$content
docs =  tm_map(docs, removeWords, stopwords("english"))
docs[[1]]$content
docs =  tm_map(docs, removePunctuation)
docs[[1]]$content
trumpDTM = DocumentTermMatrix(docs)
trumpDTM
inspect(trumpDTM)
View(inspect(trumpDTM))
inspect(trumpDTM[1:2, 1:2])
trumpDTMS = removeSparseTerms(trumpDTM, 0.05)
trumpDTMS
inspect(trumpDTM[, c("news", "fake", "america", "great")])
inspect(trumpDTM[, c("free", "russia", "news")])
trumpFreqTerms = findFreqTerms(trumpDTM, lowfreq = 50)
trumpFreqTerms
trumpFreqTerms = colSums(as.matrix(trumpDTM))
head(trumpFreqTerms)
sort(trumpFreqTerms, decreasing = TRUE)
trumpFreqTermsDF =  data.frame(word = names(trumpFreqTerms), freq = trumpFreqTerms)
trumpFreqTermsDF
library("dplyr")
arrange(trumpFreqTermsDF, desc(freq))
trumpFreqTermsDF100 = subset(trumpFreqTermsDF, freq >= 100) %>% arrange(desc(freq))
barplot(trumpFreqTermsDF100$freq, names.arg = trumpFreqTermsDF100$word)
install.packages("wordcloud")
library(wordcloud)
set.seed(142)
wordcloud(trumpFreqTermsDF$word, trumpFreqTermsDF$freq, min.freq = 25)
findAssocs(trumpDTM, "fake", corlimit = 0.6)
